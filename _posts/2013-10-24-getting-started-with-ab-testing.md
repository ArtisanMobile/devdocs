---
layout: docs
title: "A/B Testing"
author: "Artisan"
category: best-practices
description: "Getting started with the Artisan MEM platform for developers."
---

#What is A/B Testing?


Let\'s take a look at an example. Shoeco.com would like to increase registrations within their retail mobile app. They created an A/B/C experiment with the goal of increasing the percentage of people who click the \"register\" button on their product page. The control (A) and the two variations (B and C) are shown. The target selected as the goal is the \"register\" button.

Shoeco.com ran this experiment with 30,000 users over 30 days of time. Artisan tracked the conversion rates on the graph below.

At the onset of the experiment, the data was highly volatile (days 1-5). At this point of the experiment, the confidence level would be very low due to the small number of data points included in the calculation. As time progressed and more data points were included in the statistical calculations, the confidence level grew higher and the volatility decreased. At the end of the 30-day experiment, Artisan presented Shoeco.com with the following results.

Variation B had the highest conversion rate at 3.55%, which was a 7.45% increase over the control (variation A). When released to the full user base, we can be 95% statistically confident that the conversion rate will be within the range of 3.45% and 3.65% (this is the \"confidence interval\"). The control is converting at 3.30% with a confidence interval of 3.20% to 3.39%, which means that we are over 95% statistically confident that variation B will outperform the control. In addition, variation B outperformed variation C and we are also statistically confident that variation B is better than variation C. Thus, variation B is the winning variation.

##How can Artisan Optimize help?

As more consumers use their mobile devices to shop, to communicate, to research, and to be entertained, publishers and marketers face a new frontier filled with tremendous opportunities to engage and profit from mobile customers.  The fragmented application management ecosystem has made it a challenge for marketers to know when or why an app is due for an update, cumbersome and time consuming to execute that update, left to the consumer\'s discretion to download the update, and difficult to understand the impact of the update when it\'s all said and done. In this scenario, acquiring timely insight into the consumer\'s application experience and user behavior has been a lost cause.

In practice, the Artisan MEM platform offers marketers a software development environment that enables drag-and-drop native mobile application creation, testing, analysis, modification and delivery. Marketers can engage the platform to access their apps and navigate them screen-by-screen, where text and font, color, and image updates can be made instantly - with no change to the underlying code - in a content management experience that mirrors that of modern CEM and WMO tools.

##Measuring Optimization Success

A/B testing helps you improve the business performance of your app. Listed below are metrics by vertical market commonly used to measure an app\'s success.

### Mobile Commerce Revenue
* Add to cart conversion rate
* Checkout conversion rate
* Average Order Size
* Revenue per session
* Cart abandonment rate
* New buyers on mobile (first app purchase)
* Sign-in and sign-up conversions
* Guaranteed for Holiday
* Checkout conversion rate
* Referrals per User
* Cart abandonment rate
* Media Revenue
* Ad impressions
* Time in app
* Percent recurring
* Revenue per session

###Utility App/Search & Review

* Task completion/navigation
* Time in App
* Percent recurring users

###Customer Retention

* CSAT/Survey
* Percent recurring
* MAU

##What should I test?

If you are new to A/B testing, Artisan provides helpful hints below for launching your Artisan A/B testing plan.

###MCommerce
####Top of Funnel
* Homescreen CTA (text vs. Buttons)
* Images (people vs. objects)
* Registration Button/CTA
* Navigation Scroll Vertically vs. Carousel ie left to right

####Mid-Funnel
* Moving promos earlier into the funnel/show Dollars vs. % saved
* Navigation - Filter options
* Navigation - Display products in a table format or a list
* Images - Larger fewer images per screen, smaller more images per screen

####Bottom of Funnel
* Location of checkout button
* Size of checkout button
* Strength of checkout wording

###Media
####Top of Funnel
* Menu - Text, ordering of options
* Search Box - Size, location and text
* Navigation - Default to screen vs. different customizations \"Create a Station\" or \"My Stations\"

####Mid-Funnel
* Thumbnails - Navigation - Table view vs. list view
* Thumbnails - Navigation - Size and location of Thumbnail
* Text - Length of the description, does more text remove the need to watch the video or read the article?

####Bottom of Funnel
* More text less less handlines
* Ratings
* Share/invite

###Search and Review / Utility Apps
####Top of Funnel
* Search Bar - size, text, location
* Settings - Color button, CTA, size of button, location of button
* Home screen - Lists, map or images (size, quality, quantity)

####Mid-Funnel
* Menu - Options - number of things you can do, ordering, text
* Search results list view vs. on map vs. trying another search
* Favorites or Most Popular - Button sizes, text, color and location
* Different Filters - Brand, proximity, price

####Bottom of Funnel
* CTA - Text vs. Button \"Call Now\"
* Navigation - Task completion (rate) vs. backing out
* Different Payment Option - ordering, count, size, text



